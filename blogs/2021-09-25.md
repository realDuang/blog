---
title: 大型前端项目 DevOps 沉思录 —— CD 篇
categories: 架构设计
tags: 设计模式
date: 2021-09-25 18:26:27
---

:::tip
`DevOps`一词源于`Development` 和 `Operations` 的组合，即将软件交付过程中开发与测试运维的环节通过工具链打通，并通过自动化的测试与监控，减少团队的时间损耗，更加高效稳定地交付制品。

本篇文章将着重探讨 `DevOps` 在 `持续部署阶段` 需要提供的能力，介绍大型项目应该如何稳定并高频率的迭代项目版本。
:::

<!-- more -->

在系列的 [上一篇文章](https://www.zakum.cn/blogs/2021-05-11.html) 中，我们详细介绍了腾讯文档前端在 `DevOps` 的 `持续集成阶段` 所作出的实践与思考，介绍了在 CI 阶段项目工作流的设计及流水线的优化思路。

本次我们将探讨 `DevOps` 在 `持续部署阶段` 需要提供的能力，介绍大型项目应该如何稳定并高频率的迭代项目版本。

## 正确认识持续部署

我们在为一个项目搭建自动化流水线时，通常会将项目的代码检查、自动化测试、代码编译、部署环境等等环节全部放入同一条流水线，因为许多时候，这都是一条逻辑清晰且稳定的链路，能够确保发布产物一定完成了全部的自动化检查。

常见的项目流水线应该如下图所示，是一条大而全的串行链路：

![ci&cd pre](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20210927171709.png)

由于这样的 CI/CD 流水线经常被各类文章列为最佳实践，于是很多时候，我们很容易将 CI/CD 流程混为一谈，甚至将其等同于构建 `DevOps` 流水线的全流程，这种认知其实是不对的。

> 持续部署（Continuous deployment，缩写为 CD），是一种软件工程方法，意指在软件开发流程中，以自动化方式，频繁而且持续性的，将软件部署到生产环境中，使软件产品能够快速的发展。

与上一章介绍的`持续集成`不同，`持续部署`更多的是侧重在已经生成的制品如何**高频**且**低风险**的自动部署到各种测试、灰度与生产环境的。想要做到高频与稳定，我们需要彻底将`持续部署`环节从`持续集成`环节中分离出来，形成独立的流水线。

## 解耦 CI 与 CD 环节

### 为何要将 CD 从 CI 中分离

一个项目在发展成熟的过程中，代码将逐渐变得庞大且复杂，项目编译、代码检查和自动化测试的时间将不可避免的越变越长。但与此同时，高频部署与版本切换对于一个自动化成熟的项目来说也是一个必选项。尽管在`持续集成`阶段，我们可以用上篇文章介绍过的次级构建等方法来减少从代码推送到制品生成之间的耗时，但距离我们期望的快速版本切换来说仍然杯水车薪。

这个问题在现网出现致命故障回滚时暴露的尤为明显。以我们团队项目之前的实践为例，在回滚版本时，实质上是将打过`git tag`的上一版本节点抽离出分支进行一次提交，等待其执行了完整的 CI/CD 流程后在源站服务器上更新我们的 HTML 完成更新。也就是说，我们的回滚操作所需的准备时间几乎是和发布一个新版本同样长。这对于一个用户量较大的成熟项目来说是不可接受的。

其实，我们是被长时间的自动化构建思维带入了误区，认为发布流程不经过 CI 验证过就不是一个合格的产物。想要实现瞬间回滚其实很简单，我们只需要记录之前版本的发布产物，在需要回滚时直接进入服务器将之前记录过的某一版本发布到源站服务器即可。

但是这种由人工来手动选择文件并拷贝覆盖到服务器的方式显然容易出错，我们还是应该利用流水线的能力来实现这一功能，而这就是与 `持续集成` 分离后，`持续部署` 流水线的其中一个能力。

`DevOps`中所谓**持续**，是指每完成一个完整的部分，就向下个环节推进，如果发现问题可以在当前环节内调整和重试，并不会影响其他环节。以回滚为例，同一个制品已经通过了`持续集成`的测试并完成交付后，就不应该再对其进行第二次 CI 环节了，而只需重新执行`持续部署`流程即可，而通常，`持续部署`的环境切换效率是极高的，这就是将 CI 与 CD 环节解耦的意义。

### 如何分离

上一章说过，CI 的终点是将产物整理打包生成 docker image 制品，存入镜像仓库（对于制品的存放形式是 docker 镜像还是普通文件可以参看 [上一章节](https://www.zakum.cn/blogs/2021-05-11.html)，按需选择）。里面的例子中提到，由于 CI 和 CD 在流程上是解耦的，因此我们需要一个地方记录下每一个通过 CI 环节的产物。

在信息系统的设计理论中，存放唯一可信信息的地方被称为** SSOT**（Single source of truth）与 **SVOT**（Single version of truth），这样能确保我们获取的信息是真实可信的，具有权威性的。这里的可信包含两个方面，质量与安全。

> 可信质量：指开发过程中的代码质量、测试通过率、审批结果、合规性、所属人等。
>
> 可信安全：指开发过程中的代码安全风险、外部依赖安全风险、动态应用安全风险等。

每一个通过 CI 生成的制品被存入镜像仓库后，会将镜像链接、版本、CI 各流程完成结果等等信息，作为一条记录存放在 SSOT 中，而可信这一概念在制品信息中的表现，则是可以通过在该条记录中添加标签或索引来实现。

于是我们可以得到大致这样的一条记录，表明了制品的生成时间，镜像地址，仓库分支来源，质量校验结果等等一系列的信息。制品版本的对应关系一目了然。

![20211001163304](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20211001163304.png)

于是，在新思路的引导下，我们重新定义了 CI 流程的终点：生成制品并存至仓库后，为该制品设置可信标签，存入 SSOT 中成为一个可信版本。

而这条版本信息，也成为了 CD 的起点。需要部署时，只需根据标签或索引信息筛选出符合要求的最新制品信息，即可找到对应制品，部署该版本。由于制品本身已完成编译且质量合格，因此能直接安全的部署在生产环境中。从而极大的缩短了部署流程的时间。

该过程不仅作用在新版本发布中，热修复、灰度部署、回滚等产品常见的特殊部署场景全都可以使用该能力快速实现，仅需完成审批，就能全自动发布。

## 前端制品的云原生部署

### 生产能被云原生调度的合格制品

在 [CI 篇](https://www.zakum.cn/blogs/2021-05-11.html) 中曾提到，由于前端的特殊性，对于静态资源，如 js、css 等文件的网络加载时间较为敏感，同时 HTTP 请求也具备多级缓存的能力，因此这些静态资源放于源站并同步给 CDN 仍然为最优解。于是需要上云的产物便只关联用户的首次请求产物，也即 HTML 了。

一些同学可能会觉得，如果只是 HTML 这一个文件，完全不需要以一个这么重的方案来承载。这其实还是将前端的产物设想为文件这种简单的形式来考虑的。

实际上，对于稍复杂的前端项目来说，用户接收到的 HTML 返回很多都是运行时动态生成的，例如功能开关、灰度、渠道特性、SSR、ABTest 等等功能，这都是根据用户当前请求，即时地返回不同的 HTML。换言之，这里的 HTML 生成器其实是一个`Web Source Service`，更应该当做一个微服务看待。这么想来，前端服务通过云原生的方式管理是不是就合理多了？

进行到这里，我们会发现，

考虑到前端同学的习惯以及相关功能的生态，我们的 web service 使用 nodejs 来承载，

### 制定平滑的灰度策略

产品在迭代过程中，不可避免的需要对版本进行升级，进行代码修改，而修改则意味着风险。~~因此，只要不改代码就不会有风险。（划掉）~~ 因此，我们需要灰度机制来降低风险带来的影响范围。其中业界最普遍的实现方式便是大名鼎鼎的金丝雀 (canary) 发布。

> 冷知识--金丝雀发布的名称由来。
> 17 世纪，英国矿井工人发现，金丝雀对瓦斯这种气体十分敏感。空气中哪怕有极其微量的瓦斯，金丝雀也会停止歌唱；
> 当瓦斯含量超过一定限度时，虽然鲁钝的人类毫无察觉，金丝雀却早已毒发身亡。
> 当时在采矿设备相对简陋的条件下，工人们每次下井都会带上一只金丝雀作为瓦斯检测指标，以便在危险状况下紧急撤离。

传统的金丝雀发布为：选用少量的固定数量的服务器作为金丝雀部署机，将一些特定的灰度用户的流量导入到该台机器上测试新版本功能，无误后再进行全量发布。

这里会有两个地方不够灵活，一是金丝雀部署机的机器数量较为固定，扩缩容较为困难，因此要求灰度用户的访问流量峰值必须维持在一定水平，流量少了浪费机器，多了顶不住。二是灰度用户规则是写死的，例如 QQ 的灰度用户方案是以用户 id 后两位来判断是否进入灰度的，不够随机，在某些场景下有可能无法反映真实情况。

这里就揭露了为什么我们花了大力气将制品镜像化，进行云原生部署的原因之一。通过 terraform 对 k8s 的管理，这两个问题都迎刃而解了。HPA（Horizontal Pod Autoscaler）能力解决了自动扩缩容难题，而滚动发布的方式则解决了升级的平滑度，我们不在需要定义具体哪些用户，具体多少百分比进入灰度。在流水线的帮助下，一切都是缓慢且稳定进行着的。

当然，这样的灰度策略还远不够极限，为了更快速的开关灰度能力，我们甚至需要增加单版本运行时的特性开关能力，不过这就涉及到 CE（持续实验）环节了，这块的知识我们先按下不表，下次有机会再开新坑。

<!-- ## 结语

## 参考资料

1. 《持续交付 2.0》—— 乔梁 著 
2. [Google Anthos 混合云 Devops 实践](https://www.kubernetes.org.cn/8114.html)
3. [蓝绿发布、滚动发布、灰度发布等部署方案对比与总结](https://mp.weixin.qq.com/s?__biz=MzI3MTI2NzkxMA==&mid=2247485803&idx=1&sn=b967e2bdf33f933e54175dd1bdc5b07c&chksm=eac52842ddb2a1541148b386b8fe17817b7eebc6f8c94c524175e926d24e909c051b593c4baf&token=1841464039&lang=zh_CN#rd)

-->
