---
title: 前端动态制品服务云原生部署实践
categories: 架构设计
tags: 设计模式
date: 2021-09-25 18:26:27
---

说到一个服务的部署，无论是本地起一个Dev Server 用来做热加载，还是在某台服务器上起一个数据库用来实现数据通信，相信大家都有所实践。

通常由我们前端开发搭建的后台服务，多以非关键链路为主，很少会去考虑稳定性和安全性的问题。遇到特性服务出现异常时，最常见的做法就是设计一个降级策略，如果出现任何问题告警，直接手动关闭该特性，把请求切换到某一个兜底服务上。但是，在服务宕机的这段时间内用户的异常率会上升，特性功能关闭某些后用户的体验也会下降。这样的降级策略并不优雅，甚至在某些关键链路的场景下，服务宕机会导致直接白屏，这是不可接受的。

工业级别的大型软件服务对稳定性有着近乎苛刻的要求。我们在网上浏览各大厂的服务架构介绍时，有一个词总是越来越频繁的出现，那就是云原生部署。

说到云，大家很容易想到各项云服务。有同学会说了，当前各厂都推出了公有云服务，既然这项技术已经这么发达了，我随便在腾讯云上买一台CVM当服务器，在上面进行服务的开发与部署，是不是就是服务的云原生部署了？事实上，云原生部署远不是单机服务上云这么简单。

云原生是以容器、微服务、DevOps等技术为基础建立的一套架构思想，其核心其实在于服务的不可变原则，并基于此点扩展出分布式以及自动化特性。

这么说可能不太好理解，我们可以换个思路，思考下一代服务架构应该要满足什么条件：

1. 维护服务的稳定性，在任何场景下服务不能被中断，更新及回滚时要维持服务内容的**幂等性**，并对运行各迭代版本的服务做好充分的**容灾和备份**。
2. 产品版本迭代的过程要**自动化**且**无感知**，服务的部署发布复杂度不能超过旧架构。

带着这两点要求，我们来思考原始的服务部署究竟有哪些问题，以及我们可以从哪些角度做出改进。

## 服务运维模式的进化

### 0. 石器时代

![石器时代](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20210729172251.png)

让一个后台服务最快开发上线的方式，不外乎直接在物理机服务器上进行服务部署，代码变更以及服务运维全程在该服务器上进行。这也是最常见的服务部署方式，需要对服务做任何变更及版本升级时，都需要登录到服务器去操作文件内容，重启服务。在多个服务器提供负载均衡的情况下，这样的操作需要进行多次。

优化方案当然是有的，我们可以通过 git 仓库来管理版本，通过编写 shell 脚本来批量修改与重启。但无论如何这种直接操作服务器代码内容的方式都是十分危险的（删库跑路警告）。

另外，物理机不可避免的受到老化的影响，需要裁撤换新，那么无论新机器与旧机器有多么相似，架构的不同，系统版本的不同，还有一些原有系统中一些魔改的操作，都会让服务的迁移变得极为困难，有时候由于系统核心依赖的缺失而进行的迁移，其难度不亚于重写。我们需要一个与承载环境完全无关的服务来实现一处编写，随处部署的能力。

而这，其实就是 docker 的容器化思路。

### 1. 青铜时代

![青铜时代](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20210729202728.png)

容器技术提供的是操作系统级别的进程隔离，可以让服务跑在完全隔离的环境下，无视物理机自身属性，妈妈再也不用考虑我的环境的兼容性问题啦。

在 [大型前端项目 DevOps 沉思录 —— CI 篇](https://www.zakum.cn/blogs/2021-05-11.html) 中我曾简单介绍过，想要维持产物->制品服务的不可变特性，采用 docker 容器的方式包裹制品服务或许是一个最佳实践。

业务在执行前端源码编译后，进一步将产物放入制品服务的指定目录中，并构建为 Docker 镜像。之后对于任何架构的服务器，只需要拥有 docker 环境，则下载该镜像后一定能运行起来提供完全相同的服务，实现无视宿主机环境的 imutable 部署。

而最简接入的方式也很简单，只需要在项目根目录下增加 Dockerfile 的文件编写即可。

```dockerfile
# 安装完整依赖并构建产物
FROM node:14 AS build
WORKDIR /app

COPY package*.json /app/
RUN ["npm", "install"]
COPY . /app/

RUN npm run build
```

当然优化的方式有很多，具体可以参考我的 [NodeJS 服务 Docker 镜像极致优化指北](https://www.zakum.cn/blogs/2021-07-25.html)

### 2. 蒸汽时代

![蒸汽时代](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20210729213313.png)

我们的实际服务中，仅靠一个单容器可能不足以支撑所有的应用场景。拿Web的场景来说，我们可能会需要一个 redis 服务来做缓存优化，需要消息队列来实现与多后端服务的数据拉取。

这些服务并不是完全独立的，例如接口服务和数据库服务，它们需要共享同一个网络栈，挂载同一个存储卷。我们暂且将这样一个有关联依赖关系的容器集称为`Pod`。

想要将这样一个`Pod`作为逻辑整体来进行管理，就需要一个容器组织框架了。市面上的容器管理框架有几种，最典型的就是 docker-compose 了，它能很好的组织多个容器间的依赖关系，做到多依赖服务的批量部署。

常见的 docker-compose 配置形式如下，仅需声明所需的端口、环境以及依赖，即可通过 `docker-compose up` 一键启动，十分便利。

```yaml
version: '3.4'

services:
  webserver:
    image: synccheng/webserver
    environment:
      - ConnectionString=sqlserver
    expose:
      - "3306"
    ports:
      - "8000:80"
    depends_on:
      - sqlserver

  sqlserver:
    image: synccheng/sqlserver
    environment:
      - PASSWORD=[PLACEHOLDER]
    expose:
      - "3306"
    ports:
      - "5000:3306"
```

### 3. 电气时代

![电气时代](https://zakum-1252497671.cos.ap-guangzhou.myqcloud.com/20211117202703.png)

`Pod`概念的提出，解决了容器之间的关联依赖关系、共享资源等问题。但对于多个`Pod`的管理，其实也有同样的问题需要解决。例如公共服务`Pod`与单个业务服务`Pod`之间也存在关联关系。

关联`Pod`的生命周期需要进行统一管理调度。例如当版本更新，容器需要销毁重建时，公共服务一定是最先启动，最后销毁的，这样才能保证业务层依赖服务的稳定。

这里根据实际需求的不同，管理调度策略有很多，例如在当前最流行的容器编排引擎Kubernetes中，就分为Deployment、StatefulSet、DaemonSet、Replication等多种。它们出现的目的，就是解决多`Pod`间的生命周期管理问题。保证多服务更新或销毁时整体的稳定性。

当然，Kubernetes提供的能力远不止于此，作为编排引擎，它能够实现服务的自动化部署、设计多`Pod`的负载均衡、实现动态扩缩容（HPA），等等。基于镜像构建的 `imutable` 特性，在资源足够的情况下，Kubernetes能提供近乎无限的**容灾和备份**能力。

### 4. 信息时代

我们在Server的电气时代中，已经近乎完美实现了之前所要求的第一点：服务的绝对可靠。不过代价是什么呢？增加了大量的复杂度。因此这里需要一名熟悉整套流程的运维人员负责服务的维护和升级，同时他还得熟悉前端的部署流程及发布情况。这样一个角色在哪个公司恐怕都是较为稀缺的。

此时我们可以更进一步思考，如何实现要求的第二点，即在不增加前端同学的理解成本下，无感知地走这一套流程发布新版本，根据该制品的发布所处的不同环境或用途，自动配置好服务所需的各项容灾能力。这时，就轮到基础架构自动化编排工具————Terraform出场了。

Terraform 充分利用了Infrastructure as Code, 基础架构即代码的思想，以声明的方式，在配置文件中指定不同资源组中云上硬件资源的分配与管理。

```tf
terraform {
   required_providers {
     aws = {
       source = "aws.amazon.com/xxx"
     }
   }
   backend "http" {}
}

# 配置 provider
provider "aws" {
    version = "=1.0.0"
}

# 生成资源组
resource "aws_resource_group" "deployment" {
    metadata {
      name     = "duang"
      namespace = "duang-workspace"
    }
    spec {
      container {...}
      volume {...}
      ...
    }
}
```

至此，服务从服务到软硬件的运维配置自动化链路就已全部串联起来。结合之前介绍的 [DevOps持续集成流水线实践文章](https://www.zakum.cn/blogs/2021-05-11.html)，业务开发者就能仅通过push业务代码的情况下，自动搭建起来一套运维完备的环境了。

## Dockerized Web Server 的思想

一个云原生的服务架构的理论有了，接下来我们可以看看，这样一套架构该如何运用在前端开发的部署场景中。

我们可以将一次前端编译构建的产物分成两个部分，入口文件和资源文件。其中，资源文件是静态的，可以加入hash之后直接存放在云存储中做持久化存储，并提供CDN进行加速。

而入口文件是随着版本动态更新的，客户端访问时，仅需要找到正确版本的入口文件，则可以拉取到全部的资源文件，获取完整内容。而由于各级缓存的存在，如何让用户及时请求到正确版本的入口文件，一直是前端的一大痛点。

基于上面对云原生服务模式的介绍，我们知道，需要给业务的每一个前端版本制作一个不可变的服务镜像，在最基本的情况下，业务只需要自己编写一个转发服务镜像，设置好路由规则，并在指定目录位置存放好编译构建出来的入口HTML文件即可。

这样一来，每一个版本都是一个独立的服务，这样想请求到特定版本的话，向特定的容器发送请求即可。那么每一个提供版本入口的服务就可以称其为最简形式的`Dockerized Web Server`（下简称`DWS`）。

进一步的，我们可以对服务进行能力扩展。举个栗子，大家都比较熟悉的SSR。通常来说，涉及到 SSR 功能的页面都会起一个后台服务（通常是熟悉的 node 服务）来完成权限的判断、后台数据的拉取、HTML 代码片段的拼接等等操作，最后直接返回给客户端一个渲染好的首屏完整页面，以此来提高首屏速度。那么实际上，提供这个能力的后台服务其实就是DWS`里动态一种表现形式。

对于不同的前端项目，除去用来做数据直出的 SSR，还有更多的需要运行时动态判断的功能存在。例如业务想在获取 html 之前，做一些数据 prefetch，注入到 html 里，比如 A/B Test 中，设置某个 feature 的开关；又例如，请求时根据权限判断来提前预渲染某个局部元素；甚至能够根据请求路由或参数的不同，返回不同的文件，在同一版本内起到网关的作用，等等。

通常，这些功能通常都是由多级的后台服务来分别注入，或是在首屏结束之后，由客户端向各个接口发起 ajax 请求，获取到相应的权限与状态后，去改变页面展示。

很显然，既然`DWS`能够直接与后台数据交互，且通信效率较高，又能直接从本地拿到正确版本的入口文件，那么上述的这些能力完全可以整合到同一个服务内去处理，最后一步到位地返回一个最终的服务端渲染页面。

经过上述的设计，我们还可以发现，这种服务本身是与业务无关的，可以统一建立，分布式部署的。业务甚至都不需要了解和编写dockerfile，仅需要引入统一的`DWS`框架，并将构建的产物移动到镜像内，即可借助流水线，自动完成一个`DWS`的打包与部署。

## 健壮与安全性

一旦接受了`前端制品即服务后`，对于前端来说，每个迭代版本需要交付和维护的内容就从普通的 HTML 文件转移到了这个`动态制品服务`。

除了之前介绍的，除了借助云原生服务架构有足够的稳定性保证外，我们还需要做到完善的监控与容错。
 

## 开放式的能力插件化

